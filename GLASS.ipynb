{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c85709a-58d5-4ddd-b038-ced778724222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement scann (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for scann\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tf_keras in ./venv/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in ./venv/lib/python3.10/site-packages (from tf_keras) (2.18.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.16.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.20.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.67.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.32.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.5.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.26.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (4.12.2)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.6.3)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (65.5.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (24.2)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.6.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.4.1)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (24.3.25)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf_keras) (0.44.0)\n",
      "Requirement already satisfied: namex in ./venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.0.8)\n",
      "Requirement already satisfied: optree in ./venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.13.1)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (13.9.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.1.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./venv/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets\n",
    "!pip install -q scann\n",
    "!pip install tf_keras\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73f70d39-41a8-4470-a3b1-37cdc95892e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a459e82-53b5-484b-a4b2-2708112a4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/zack/Documents/GLASS/completed-components.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6fdef240-817a-40c1-ab2d-55d4b54a9a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    \"/Users/zack/Documents/GLASS/completed-components.csv\",\n",
    "    batch_size=1,  # Adjust batch size as needed\n",
    "    select_columns=['user_id', 'title'],  # Only load the desired columns\n",
    "    label_name=None,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "components = tf.data.experimental.make_csv_dataset(\n",
    "    \"/Users/zack/Documents/GLASS/completed-components.csv\",\n",
    "    batch_size=1,  # Adjust batch size as needed\n",
    "    select_columns=['title'],  # Only load the desired columns\n",
    "    label_name=None,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def dataset_map_and_squeeze(features):\n",
    "    # Use tf.squeeze() to remove the (None,) dimension and make it ()\n",
    "    title = tf.squeeze(features['title'])  # Squeeze to shape ()\n",
    "    user_id = tf.squeeze(features['user_id'])  # Squeeze to shape ()\n",
    "    title = tf.ensure_shape(title, ())\n",
    "    user_id = tf.ensure_shape(user_id, ())\n",
    "    return {\"title\": title, \"user_id\": user_id}\n",
    "\n",
    "def components_map_and_squeeze(features):\n",
    "    # Use tf.squeeze() to remove the (None,) dimension and make it ()\n",
    "    title = tf.squeeze(features['title'])  # Squeeze to shape ()\n",
    "    title = tf.ensure_shape(title, ())\n",
    "    return title\n",
    "\n",
    "# mapped_dataset = dataset.map(lambda x: {\n",
    "#     \"title\": x[\"title\"],\n",
    "#     \"user_id\": x[\"user_id\"],\n",
    "# })\n",
    "\n",
    "mapped_dataset = dataset.map(dataset_map_and_squeeze)\n",
    "\n",
    "components = components.map(components_map_and_squeeze)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "194a6fb3-3fce-4ca3-b015-92f7a8c1a8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.map_op._MapDataset'>\n",
      "<_MapDataset element_spec={'title': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_id': TensorSpec(shape=(), dtype=tf.string, name=None)}>\n",
      "<class 'tensorflow.python.data.ops.map_op._MapDataset'>\n",
      "<_MapDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
     ]
    }
   ],
   "source": [
    "print(type(mapped_dataset))\n",
    "print(mapped_dataset)\n",
    "print(type(components))\n",
    "print(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a9cc1cd-fcf1-401f-b398-3c527381e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = mapped_dataset.shuffle(600, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(480)\n",
    "test = shuffled.skip(480).take(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e4f88499-288e-49db-acc9-8b6ca3bcf4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(user_ids) =  [<tf.Tensor: shape=(575,), dtype=string, numpy=\n",
      "array([b'Ai-Che', b'Ai-Che', b'Ai-Che', b'Ai-Che', b'Ai-Che', b'Ai-Che',\n",
      "       b'Ai-Che', b'Ai-Che', b'Ai-Che', b'Ai-Che', b'Ai-Che', b'Ai-Che',\n",
      "       b'Ai-Che', b'Ai-Che', b'Ci-Che', b'Ci-Che', b'Ci-Che', b'Ci-Che',\n",
      "       b'Ci-Che', b'Ci-Che', b'Ci-Che', b'Ci-Che', b'Ci-Che', b'Ci-Che',\n",
      "       b'Ci-Che', b'Ci-Che', b'Cu-Com', b'Cu-Com', b'Cu-Com', b'Cu-Com',\n",
      "       b'Cu-Com', b'Cu-Com', b'Cu-Com', b'Cu-Com', b'Cu-Com', b'Cu-Com',\n",
      "       b'Cu-Com', b'Cu-Com', b'Cn-Che', b'Cn-Che', b'Cn-Che', b'Cn-Che',\n",
      "       b'Cn-Che', b'Cn-Che', b'Cn-Che', b'Cn-Che', b'Cn-Che', b'Cn-Che',\n",
      "       b'Cn-Che', b'Cn-Che', b'Cn-Che', b'Dt-Che', b'Dt-Che', b'Dt-Che',\n",
      "       b'Dt-Che', b'Dt-Che', b'Dt-Che', b'Dt-Che', b'Dt-Che', b'Dt-Che',\n",
      "       b'Dt-Che', b'Dt-Che', b'Dt-Che', b'Dt-Che', b'Dt-Che', b'Dg-Com',\n",
      "       b'Dg-Com', b'Dg-Com', b'Dg-Com', b'Dg-Com', b'Dg-Com', b'Dg-Com',\n",
      "       b'Dg-Com', b'Dg-Com', b'Dg-Com', b'Dg-Com', b'Dg-Com', b'Dg-Com',\n",
      "       b'Dg-Com', b'Dg-Com', b'Dg-Com', b'Dg-Com', b'Dg-Com', b'Dg-Com',\n",
      "       b'Dg-Com', b'Dg-Com', b'Ee-Com', b'Ee-Com', b'Ee-Com', b'Ee-Com',\n",
      "       b'Ee-Com', b'Ee-Com', b'Ee-Com', b'Ee-Com', b'Ee-Com', b'Ee-Com',\n",
      "       b'Ee-Com', b'Ee-Com', b'Ee-Com', b'Ee-Mec', b'Ee-Mec', b'Ee-Mec',\n",
      "       b'Ee-Mec', b'Ee-Mec', b'Ee-Mec', b'Ee-Mec', b'Ee-Mec', b'Ee-Mec',\n",
      "       b'Ee-Mec', b'Ee-Mec', b'Ee-Mec', b'Gi-Com', b'Gi-Com', b'Gi-Com',\n",
      "       b'Gi-Com', b'Gi-Com', b'Gi-Com', b'Gi-Com', b'Gi-Com', b'Gi-Com',\n",
      "       b'Gi-Com', b'Gi-Com', b'Gi-Com', b'Jg-Com', b'Jg-Com', b'Jg-Com',\n",
      "       b'Jg-Com', b'Jg-Com', b'Jg-Com', b'Jg-Com', b'Jg-Com', b'Jg-Com',\n",
      "       b'Jg-Com', b'Jg-Com', b'Jg-Com', b'Jg-Bio', b'Jg-Bio', b'Jg-Bio',\n",
      "       b'Jg-Bio', b'Jg-Bio', b'Jg-Bio', b'Jg-Bio', b'Jg-Bio', b'Jg-Bio',\n",
      "       b'Jg-Bio', b'Jg-Bio', b'Jg-Bio', b'Jg-Bio', b'Jm-Che', b'Jm-Che',\n",
      "       b'Jm-Che', b'Jm-Che', b'Jm-Che', b'Jm-Che', b'Jm-Che', b'Jm-Che',\n",
      "       b'Jm-Che', b'Jm-Che', b'Jm-Che', b'Jm-Che', b'Jm-Che', b'Jm-Che',\n",
      "       b'Jm-Che', b'Jm-Che', b'Jm-Che', b'Jm-Che', b'Jm-Che', b'Je-Che',\n",
      "       b'Je-Che', b'Je-Che', b'Je-Che', b'Je-Che', b'Je-Che', b'Je-Che',\n",
      "       b'Je-Che', b'Je-Che', b'Je-Che', b'Je-Che', b'Je-Che', b'Je-Che',\n",
      "       b'Je-Che', b'Je-Che', b'Je-Che', b'Je-Che', b'Je-Che', b'Je-Che',\n",
      "       b'Je-Che', b'Je-Che', b'Je-Che', b'Je-Che', b'Je-Che', b'Je-Che',\n",
      "       b'Mz-Com', b'Mz-Com', b'Mz-Com', b'Mz-Com', b'Mz-Com', b'Mz-Com',\n",
      "       b'Mz-Com', b'Mz-Com', b'Mz-Com', b'Mz-Com', b'Mz-Com', b'Mz-Com',\n",
      "       b'Na-Com', b'Na-Com', b'Na-Com', b'Na-Com', b'Na-Com', b'Na-Com',\n",
      "       b'Na-Com', b'Na-Com', b'Na-Com', b'Na-Com', b'Na-Com', b'Na-Com',\n",
      "       b'Na-Com', b'Rr-\"Su', b'Rr-\"Su', b'Rr-\"Su', b'Rr-\"Su', b'Rr-\"Su',\n",
      "       b'Rr-\"Su', b'Rr-\"Su', b'Rr-\"Su', b'Rr-\"Su', b'Rr-\"Su', b'Rr-\"Su',\n",
      "       b'Rr-\"Su', b'Rr-\"Su', b'Rr-\"Su', b'Rr-\"Su', b'Sn-Bio', b'Sn-Bio',\n",
      "       b'Sn-Bio', b'Sn-Bio', b'Sn-Bio', b'Sn-Bio', b'Sn-Bio', b'Sn-Bio',\n",
      "       b'Sn-Bio', b'Sn-Bio', b'Sn-Bio', b'Sn-Bio', b'Sn-Bio', b'Vn-Mec',\n",
      "       b'Vn-Mec', b'Vn-Mec', b'Vn-Mec', b'Vn-Mec', b'Vn-Mec', b'Vn-Mec',\n",
      "       b'Vn-Mec', b'Vn-Mec', b'Vn-Mec', b'Vn-Mec', b'Vn-Mec', b'Vn-Mec',\n",
      "       b'Vn-Mec', b'Vn-Mec', b'Vn-Mec', b'Vn-Mec', b'Ym-Com', b'Ym-Com',\n",
      "       b'Ym-Com', b'Ym-Com', b'Ym-Com', b'Ym-Com', b'Ym-Com', b'Ym-Com',\n",
      "       b'Ym-Com', b'Ym-Com', b'Ym-Com', b'Ym-Com', b'Ym-Com', b'A -Bio',\n",
      "       b'A -Bio', b'A -Bio', b'A -Bio', b'A -Bio', b'A -Bio', b'Ai-Com',\n",
      "       b'Ai-Com', b'Ai-Com', b'Ai-Com', b'Ai-Com', b'Ai-Com', b'As-Bus',\n",
      "       b'As-Bus', b'As-Bus', b'As-Bus', b'As-Bus', b'As-Bus', b'As-Bus',\n",
      "       b'As-Bus', b'As-Bus', b'Bl-Che', b'Bl-Che', b'Bl-Che', b'Bl-Che',\n",
      "       b'Bl-Che', b'Bl-Che', b'Bl-Che', b'Bl-Che', b'Dg-Che', b'Dg-Che',\n",
      "       b'Dg-Che', b'Dg-Che', b'Dg-Che', b'Dg-Che', b'Dg-Che', b'Dg-Che',\n",
      "       b'En-Bio', b'En-Bio', b'En-Bio', b'En-Bio', b'En-Bio', b'En-Bio',\n",
      "       b'En-Bio', b'En-Bio', b'Ei-Che', b'Ei-Che', b'Ei-Che', b'Ei-Che',\n",
      "       b'Ei-Che', b'Ei-Che', b'Ei-Che', b'Ei-Che', b'Ee-Com', b'Ee-Com',\n",
      "       b'Ee-Com', b'Ee-Com', b'Ee-Com', b'Ee-Com', b'Ee-Com', b'Ee-Com',\n",
      "       b'En-Int', b'En-Int', b'En-Int', b'En-Int', b'En-Int', b'En-Int',\n",
      "       b'En-Int', b'En-Int', b'En-Int', b'En-Int', b'Ii-Bio', b'Ii-Bio',\n",
      "       b'Ii-Bio', b'Ii-Bio', b'Ii-Bio', b'Ii-Bio', b'Ii-Bio', b'Ii-Bio',\n",
      "       b'Ii-Bio', b'Ii-Bio', b'Ia-Mec', b'Ia-Mec', b'Ia-Mec', b'Ia-Mec',\n",
      "       b'Ia-Mec', b'Ia-Mec', b'Ia-Mec', b'Ia-Mec', b'Mg-Com', b'Mg-Com',\n",
      "       b'Mg-Com', b'Mg-Com', b'Mg-Com', b'Mg-Com', b'Mg-Com', b'Mg-Com',\n",
      "       b'Mg-Com', b'Mg-Com', b'Ma-Com', b'Ma-Com', b'Ma-Com', b'Ma-Com',\n",
      "       b'Ma-Com', b'Ma-Com', b'Ma-Com', b'Ma-Com', b'Ma-Com', b'Ne-Com',\n",
      "       b'Ne-Com', b'Ne-Com', b'Ne-Com', b'Ne-Com', b'Ne-Com', b'Ne-Com',\n",
      "       b'Ne-Com', b'Ne-Com', b'Ne-Com', b'Ne-Com', b'Pe-Che', b'Pe-Che',\n",
      "       b'Pe-Che', b'Pe-Che', b'Pe-Che', b'Pe-Che', b'Pe-Che', b'Pe-Che',\n",
      "       b'Pe-Che', b'Re-Com', b'Re-Com', b'Re-Com', b'Re-Com', b'Re-Com',\n",
      "       b'Re-Com', b'Re-Com', b'Re-Com', b'Ra-Mat', b'Ra-Mat', b'Ra-Mat',\n",
      "       b'Ra-Mat', b'Ra-Mat', b'Ra-Mat', b'Ra-Mat', b'Ra-Mat', b'S -Bio',\n",
      "       b'S -Bio', b'S -Bio', b'S -Bio', b'S -Bio', b'S -Bio', b'S -Bio',\n",
      "       b'S -Bio', b'St-Che', b'St-Che', b'St-Che', b'St-Che', b'St-Che',\n",
      "       b'St-Che', b'St-Che', b'St-Che', b'To-Com', b'To-Com', b'To-Com',\n",
      "       b'To-Com', b'To-Mec', b'To-Mec', b'To-Mec', b'To-Mec', b'To-Mec',\n",
      "       b'To-Mec', b'To-Mec', b'To-Mec', b'To-Mec', b'Vg-Com', b'Vg-Com',\n",
      "       b'Vg-Com', b'Vg-Com', b'Vg-Com', b'Vg-Com', b'Vg-Com', b'Vg-Com',\n",
      "       b'Zn-Com', b'Zn-Com', b'Zn-Com', b'Zn-Com', b'Zn-Com', b'Zn-Com',\n",
      "       b'Zn-Com', b'Zn-Com', b'Zn-Com', b'Aa-Com', b'Aa-Com', b'Aa-Com',\n",
      "       b'Aa-Com', b'Ar-Ele', b'Ar-Ele', b'Ar-Ele', b'Ar-Ele', b'Ah-Com',\n",
      "       b'Ah-Com', b'Ah-Com', b'Ah-Com', b'Ah-Com', b'Ah-Com', b'Ad-Mec',\n",
      "       b'Ad-Mec', b'Ad-Mec', b'Ad-Mec', b'Ad-Mec', b'Ad-Mec', b'Ad-Mec',\n",
      "       b'An-Bio', b'An-Bio', b'An-Bio', b'An-Bio', b'An-Bio', b'Ad-Civ',\n",
      "       b'Ad-Civ', b'Ad-Civ', b'Ad-Civ', b'Ck-Bus', b'Ck-Bus', b'Ck-Bus',\n",
      "       b'Ck-Bus', b'Ck-Bus', b'Cl-Com', b'Cl-Com', b'Cl-Com', b'Cl-Com',\n",
      "       b'Cl-Com', b'Cl-Com', b'Eg-App', b'Eg-App', b'Eg-App', b'Eg-App',\n",
      "       b'Ea-Ele', b'Ea-Ele', b'Ea-Ele', b'Ea-Ele', b'Ea-Ele', b'Ea-Ele',\n",
      "       b'Ea-Ele', b'Ea-Ele', b'Ey-Mat', b'Ey-Mat', b'Ey-Mat', b'Ey-Mat',\n",
      "       b'Fy-Bio', b'Fy-Bio', b'Fy-Bio', b'Fy-Bio', b'Fy-Bio', b'Fy-Bio',\n",
      "       b'Fy-Bio', b'Hn-Mat', b'Hn-Mat', b'Hn-Mat', b'Hn-Mat', b'Hn-Mat',\n",
      "       b'Jn-Civ', b'Jn-Civ', b'Jn-Civ', b'Jn-Civ', b'Kh-Com', b'Kh-Com',\n",
      "       b'Kh-Com', b'Kh-Com', b'Kg-Com', b'Kg-Com', b'Kg-Com', b'Kg-Com',\n",
      "       b'Kg-Com', b'Ka-Mec', b'Ka-Mec', b'Ka-Mec', b'Ka-Mec', b'Mg-Mec',\n",
      "       b'Mg-Mec', b'Mg-Mec', b'Mg-Mec', b'Mg-Mec', b'Mg-Mec', b'Sg-\"Su',\n",
      "       b'Sg-\"Su', b'Sg-\"Su', b'Sg-\"Su', b'Ta-Bio', b'Ta-Bio', b'Ta-Bio',\n",
      "       b'Ta-Bio', b'Vo-Bus', b'Vo-Bus', b'Vo-Bus', b'Vo-Bus', b'Vo-Bus',\n",
      "       b'Vo-Bus', b'Vo-Bus', b'Ii-Ele', b'Td-Com', b'Td-Com'],\n",
      "      dtype=object)>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([b' NYU CBE Department Research Seminars',\n",
       "       b\"'girlsnight' Fashion Week Rave for Gaza\",\n",
       "       b'2022 Boston Computer Vision Summit',\n",
       "       b'2023 - 2024 Undergraduate Student Leader of The Year',\n",
       "       b'2023 Breast Cancer March',\n",
       "       b'2023 International Conference on Information Technology and Contemporary Sports (TCS)',\n",
       "       b'2023 SHPE National Convention',\n",
       "       b'2024 18th European Conference on Antennas and Propagation (EuCAP)',\n",
       "       b'3D Printed Biomedical Devices VIP',\n",
       "       b'8th Annual GI Web Conference: Embankment, Dams, and Slopes Extereme Event Research and Trends'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components_titles = components.batch(60)\n",
    "user_ids = mapped_dataset.batch(6000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "# print(\"list(components_titles) = \", list(components_titles))\n",
    "print(\"list(user_ids) = \", list(user_ids))\n",
    "\n",
    "unique_component_titles = np.unique(np.concatenate(list(components_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "unique_component_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "65679666-1faa-409a-b4f1-5d445eacb806",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_vocabulary=tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dde4f5a1-fb9c-4fd6-bda3-9a0f581831bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_titles_vocabulary=tf.keras.layers.StringLookup(vocabulary=unique_component_titles, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bb2906f7-8e44-4bdc-b7cf-75c97112799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a6e1f1b9-9ac9-458b-b5da-8c20ce7bc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "component_model = tf.keras.Sequential([\n",
    "    component_titles_vocabulary,\n",
    "    tf.keras.layers.Embedding(component_titles_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "\n",
    "# Define your objectives.\n",
    "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "    components.batch(128).map(component_model)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "84a0870e-6aec-4c0f-ae60-3bf3dedd7f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLASSComponentModel(tfrs.Model):\n",
    "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "  # these are still plain Keras Models.\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      user_model: tf.keras.Model,\n",
    "      component_model: tf.keras.Model,\n",
    "      task: tfrs.tasks.Retrieval):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and component representations.\n",
    "    self.user_model = user_model\n",
    "    self.component_model = component_model\n",
    "\n",
    "    # Set up a retrieval task.\n",
    "    self.task = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed.\n",
    "\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    component_embeddings = self.component_model(features[\"title\"])\n",
    "\n",
    "    return self.task(user_embeddings, component_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9e241be9-a17c-4df3-aca2-3593bab553fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adagrad` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adagrad`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 1s 636ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0139 - factorized_top_k/top_5_categorical_accuracy: 0.2070 - factorized_top_k/top_10_categorical_accuracy: 0.5061 - factorized_top_k/top_50_categorical_accuracy: 0.8800 - factorized_top_k/top_100_categorical_accuracy: 0.9496 - loss: 9971.3643 - regularization_loss: 0.0000e+00 - total_loss: 9971.3643\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 57ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0122 - factorized_top_k/top_5_categorical_accuracy: 0.1757 - factorized_top_k/top_10_categorical_accuracy: 0.4243 - factorized_top_k/top_50_categorical_accuracy: 0.6974 - factorized_top_k/top_100_categorical_accuracy: 0.8017 - loss: 12509.9482 - regularization_loss: 0.0000e+00 - total_loss: 12509.9482\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 66ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0209 - factorized_top_k/top_5_categorical_accuracy: 0.2365 - factorized_top_k/top_10_categorical_accuracy: 0.5148 - factorized_top_k/top_50_categorical_accuracy: 0.7965 - factorized_top_k/top_100_categorical_accuracy: 0.8783 - loss: 11321.3887 - regularization_loss: 0.0000e+00 - total_loss: 11321.3887\n",
      "Top 10 recommendations for user: [b'Promoted to Senior Writing Consultant '\n",
      " b'3D Printed Biomedical Devices VIP' b'TUSC Director of Programming '\n",
      " b'NYU Abu Dhabi Study Abroad ' b'Indonesia J-Term'\n",
      " b'University Leadership Honors Course (ULHC)'\n",
      " b'NYU Florence Study Abroad' b'NYU Florence Study Abroad'\n",
      " b'VIP Experimental Team Leader' b'NYU MakerSpace Events ']\n"
     ]
    }
   ],
   "source": [
    "# Create a retrieval model.\n",
    "model = GLASSComponentModel(user_model, component_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "# Train for 3 epochs.\n",
    "model.fit(mapped_dataset.batch(4096), epochs=3)\n",
    "\n",
    "# Use brute-force search to set up retrieval using the trained representations.\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "    components.batch(100).map(lambda title: (title, model.component_model(title))))\n",
    "\n",
    "# Get some recommendations.\n",
    "\n",
    "_, titles = index(np.array([\"S -Bio\"]))\n",
    "print(f\"Top 10 recommendations for user: {titles[0, :10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381fc6d-2924-467a-abc4-d7fc6efa66dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
