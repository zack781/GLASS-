{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c85709a-58d5-4ddd-b038-ced778724222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement scann (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for scann\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tf_keras in ./venv/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in ./venv/lib/python3.10/site-packages (from tf_keras) (2.18.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.16.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.20.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.67.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.32.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.5.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.26.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (4.12.2)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.6.3)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (65.5.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (24.2)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.6.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.4.1)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (24.3.25)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf_keras) (0.44.0)\n",
      "Requirement already satisfied: namex in ./venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.0.8)\n",
      "Requirement already satisfied: optree in ./venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.13.1)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (13.9.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.1.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./venv/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets\n",
    "!pip install -q scann\n",
    "!pip install tf_keras\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73f70d39-41a8-4470-a3b1-37cdc95892e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a459e82-53b5-484b-a4b2-2708112a4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/zack/Documents/GLASS/completed-components.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6fdef240-817a-40c1-ab2d-55d4b54a9a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    \"/Users/zack/Documents/GLASS/completed-components.csv\",\n",
    "    batch_size=1,  # Adjust batch size as needed\n",
    "    select_columns=['user_id', 'title'],  # Only load the desired columns\n",
    "    label_name=None,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "components = tf.data.experimental.make_csv_dataset(\n",
    "    \"/Users/zack/Documents/GLASS/completed-components.csv\",\n",
    "    batch_size=1,  # Adjust batch size as needed\n",
    "    select_columns=['title'],  # Only load the desired columns\n",
    "    label_name=None,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def map_and_squeeze(features):\n",
    "    # Use tf.squeeze() to remove the (None,) dimension and make it ()\n",
    "    title = tf.squeeze(features['title'])  # Squeeze to shape ()\n",
    "    user_id = tf.squeeze(features['user_id'])  # Squeeze to shape ()\n",
    "    title = tf.ensure_shape(title, ())\n",
    "    user_id = tf.ensure_shape(user_id, ())\n",
    "    return {\"title\": title, \"user_id\": user_id}\n",
    "\n",
    "mapped_dataset = dataset.map(lambda x: {\n",
    "    \"title\": x[\"title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "})\n",
    "\n",
    "mapped_dataset = dataset.map(map_and_squeeze)\n",
    "\n",
    "components = components.map(lambda x: x[\"title\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "194a6fb3-3fce-4ca3-b015-92f7a8c1a8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.map_op._MapDataset'>\n",
      "<_MapDataset element_spec={'title': TensorSpec(shape=<unknown>, dtype=tf.string, name=None), 'user_id': TensorSpec(shape=<unknown>, dtype=tf.string, name=None)}>\n",
      "<class 'tensorflow.python.data.ops.map_op._MapDataset'>\n",
      "<_MapDataset element_spec=TensorSpec(shape=(None,), dtype=tf.string, name=None)>\n"
     ]
    }
   ],
   "source": [
    "print(type(mapped_dataset))\n",
    "print(mapped_dataset)\n",
    "print(type(components))\n",
    "print(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a9cc1cd-fcf1-401f-b398-3c527381e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = mapped_dataset.shuffle(600, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(480)\n",
    "test = shuffled.skip(480).take(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4f88499-288e-49db-acc9-8b6ca3bcf4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b' NYU CBE Department Research Seminars',\n",
       "       b\"'girlsnight' Fashion Week Rave for Gaza\",\n",
       "       b'2022 Boston Computer Vision Summit',\n",
       "       b'2023 - 2024 Undergraduate Student Leader of The Year',\n",
       "       b'2023 Breast Cancer March',\n",
       "       b'2023 International Conference on Information Technology and Contemporary Sports (TCS)',\n",
       "       b'2023 SHPE National Convention',\n",
       "       b'2024 18th European Conference on Antennas and Propagation (EuCAP)',\n",
       "       b'3D Printed Biomedical Devices VIP',\n",
       "       b'8th Annual GI Web Conference: Embankment, Dams, and Slopes Extereme Event Research and Trends'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components_titles = components.batch(60)\n",
    "user_ids = mapped_dataset.batch(6000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_component_titles = np.unique(np.concatenate(list(components_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "unique_component_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65679666-1faa-409a-b4f1-5d445eacb806",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_vocabulary=tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dde4f5a1-fb9c-4fd6-bda3-9a0f581831bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_titles_vocabulary=tf.keras.layers.StringLookup(vocabulary=unique_component_titles, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb2906f7-8e44-4bdc-b7cf-75c97112799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6e1f1b9-9ac9-458b-b5da-8c20ce7bc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "component_model = tf.keras.Sequential([\n",
    "    component_titles_vocabulary,\n",
    "    tf.keras.layers.Embedding(component_titles_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "\n",
    "# Define your objectives.\n",
    "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "    components.batch(128).map(component_model)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84a0870e-6aec-4c0f-ae60-3bf3dedd7f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLASSComponentModel(tfrs.Model):\n",
    "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "  # these are still plain Keras Models.\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      user_model: tf.keras.Model,\n",
    "      component_model: tf.keras.Model,\n",
    "      task: tfrs.tasks.Retrieval):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and component representations.\n",
    "    self.user_model = user_model\n",
    "    self.component_model = component_model\n",
    "\n",
    "    # Set up a retrieval task.\n",
    "    self.task = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed.\n",
    "\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    component_embeddings = self.component_model(features[\"title\"])\n",
    "\n",
    "    return self.task(user_embeddings, component_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e241be9-a17c-4df3-aca2-3593bab553fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adagrad` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adagrad`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MapDataset element_spec={'title': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'user_id': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 1381, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"/var/folders/rz/nth7hzw57x52qnhl6pxxgd440000gn/T/ipykernel_66748/3160127454.py\", line 25, in compute_loss\n        return self.task(user_embeddings, component_embeddings)\n    File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/rz/nth7hzw57x52qnhl6pxxgd440000gn/T/__autograph_generated_filezwpylgnk.py\", line 123, in tf__call\n        loss = ag__.converted_call(ag__.ld(self)._loss, (), dict(y_true=ag__.ld(labels), y_pred=ag__.ld(scores), sample_weight=ag__.ld(sample_weight)), fscope)\n\n    ValueError: Exception encountered when calling layer 'retrieval_2' (type Retrieval).\n    \n    in user code:\n    \n        File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tensorflow_recommenders/tasks/retrieval.py\", line 188, in call  *\n            loss = self._loss(y_true=labels, y_pred=scores, sample_weight=sample_weight)\n        File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/losses.py\", line 143, in __call__  **\n            losses = call_fn(y_true, y_pred)\n        File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/losses.py\", line 270, in call  **\n            return ag_fn(y_true, y_pred, **self._fn_kwargs)\n        File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/losses.py\", line 2221, in categorical_crossentropy\n            return backend.categorical_crossentropy(\n        File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/backend.py\", line 5575, in categorical_crossentropy\n            target.shape.assert_is_compatible_with(output.shape)\n    \n        ValueError: Shapes (None, None) and (None, None, None) are incompatible\n    \n    \n    Call arguments received by layer 'retrieval_2' (type Retrieval):\n      • query_embeddings=tf.Tensor(shape=(None, None, 64), dtype=float32)\n      • candidate_embeddings=tf.Tensor(shape=(None, None, 64), dtype=float32)\n      • sample_weight=None\n      • candidate_sampling_probability=None\n      • candidate_ids=None\n      • compute_metrics=True\n      • compute_batch_metrics=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m mapped_dataset\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m4096\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(mapped_dataset)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapped_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Use brute-force search to set up retrieval using the trained representations.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m index \u001b[38;5;241m=\u001b[39m tfrs\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mfactorized_top_k\u001b[38;5;241m.\u001b[39mBruteForce(model\u001b[38;5;241m.\u001b[39muser_model)\n",
      "File \u001b[0;32m~/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/rz/nth7hzw57x52qnhl6pxxgd440000gn/T/__autograph_generated_fileogg2ymhm.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tensorflow_recommenders/models/base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 68\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m   \u001b[38;5;66;03m# Handle regularization losses as well.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m   regularization_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n",
      "Cell \u001b[0;32mIn[47], line 25\u001b[0m, in \u001b[0;36mGLASSComponentModel.compute_loss\u001b[0;34m(self, features, training)\u001b[0m\n\u001b[1;32m     22\u001b[0m user_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_model(features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     23\u001b[0m component_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_model(features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent_embeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/folders/rz/nth7hzw57x52qnhl6pxxgd440000gn/T/__autograph_generated_filezwpylgnk.py:123\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, query_embeddings, candidate_embeddings, sample_weight, candidate_sampling_probability, candidate_ids, compute_metrics, compute_batch_metrics)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    122\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_num_hard_negatives \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, if_body_4, else_body_4, get_state_4, set_state_4, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 123\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m update_ops \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_5\u001b[39m():\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 1381, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"/var/folders/rz/nth7hzw57x52qnhl6pxxgd440000gn/T/ipykernel_66748/3160127454.py\", line 25, in compute_loss\n        return self.task(user_embeddings, component_embeddings)\n    File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/rz/nth7hzw57x52qnhl6pxxgd440000gn/T/__autograph_generated_filezwpylgnk.py\", line 123, in tf__call\n        loss = ag__.converted_call(ag__.ld(self)._loss, (), dict(y_true=ag__.ld(labels), y_pred=ag__.ld(scores), sample_weight=ag__.ld(sample_weight)), fscope)\n\n    ValueError: Exception encountered when calling layer 'retrieval_2' (type Retrieval).\n    \n    in user code:\n    \n        File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tensorflow_recommenders/tasks/retrieval.py\", line 188, in call  *\n            loss = self._loss(y_true=labels, y_pred=scores, sample_weight=sample_weight)\n        File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/losses.py\", line 143, in __call__  **\n            losses = call_fn(y_true, y_pred)\n        File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/losses.py\", line 270, in call  **\n            return ag_fn(y_true, y_pred, **self._fn_kwargs)\n        File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/losses.py\", line 2221, in categorical_crossentropy\n            return backend.categorical_crossentropy(\n        File \"/Users/zack/Documents/GLASS/glasspp/venv/lib/python3.10/site-packages/tf_keras/src/backend.py\", line 5575, in categorical_crossentropy\n            target.shape.assert_is_compatible_with(output.shape)\n    \n        ValueError: Shapes (None, None) and (None, None, None) are incompatible\n    \n    \n    Call arguments received by layer 'retrieval_2' (type Retrieval):\n      • query_embeddings=tf.Tensor(shape=(None, None, 64), dtype=float32)\n      • candidate_embeddings=tf.Tensor(shape=(None, None, 64), dtype=float32)\n      • sample_weight=None\n      • candidate_sampling_probability=None\n      • candidate_ids=None\n      • compute_metrics=True\n      • compute_batch_metrics=True\n"
     ]
    }
   ],
   "source": [
    "# Create a retrieval model.\n",
    "model = GLASSComponentModel(user_model, component_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "# Train for 3 epochs.\n",
    "mapped_dataset.batch(4096)\n",
    "print(mapped_dataset)\n",
    "model.fit(mapped_dataset.batch(4096), epochs=3)\n",
    "\n",
    "# Use brute-force search to set up retrieval using the trained representations.\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "#index.index_from_dataset(\n",
    "#    components.batch(100).map(lambda title: (title, model.component_model(title))))\n",
    "\n",
    "# Get some recommendations.\n",
    "#_, titles = index(np.array([\"42\"]))\n",
    "#print(f\"Top 3 recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381fc6d-2924-467a-abc4-d7fc6efa66dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
